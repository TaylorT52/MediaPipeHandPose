{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mediapipe in /Users/taylor/Library/Python/3.9/lib/python/site-packages (0.9.1.0)\n",
      "Requirement already satisfied: opencv-python in /Users/taylor/Library/Python/3.9/lib/python/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: absl-py in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from mediapipe) (3.8.2)\n",
      "Requirement already satisfied: numpy in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from mediapipe) (1.26.3)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib->mediapipe) (6.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ultralytics in /Users/taylor/Library/Python/3.9/lib/python/site-packages (8.1.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (1.26.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (0.16.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: psutil in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (5.9.7)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (2.1.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from ultralytics) (0.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from matplotlib>=3.3.0->ultralytics) (6.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from requests>=2.23.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
      "Requirement already satisfied: filelock in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from torch>=1.8.0->ultralytics) (2023.12.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pybboxes in /Users/taylor/Library/Python/3.9/lib/python/site-packages (0.1.6)\n",
      "Requirement already satisfied: numpy in /Users/taylor/Library/Python/3.9/lib/python/site-packages (from pybboxes) (1.26.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python\n",
    "!pip install ultralytics\n",
    "!pip install pybboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import os\n",
    "from ultralytics.utils.plotting import Annotator \n",
    "import json\n",
    "from google.protobuf.json_format import MessageToDict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load YOLO stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_loc = \"/Users/taylor/runs/detect/train14/weights/best.pt\"\n",
    "yolo_model = YOLO(weights_loc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hand poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = 30\n",
    "img_counter = 0\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "desired_aspect_ratio = 1 \n",
    "standard_size = (350, 350)\n",
    "handedness = \"\"\n",
    "gestures = [\"speed_inc\", \"speed_dec\", \"to_right\", \"to_left\"]\n",
    "\n",
    "with open(\"base_gestures.json\", \"r\") as infile:\n",
    "    data = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower_pink = np.array([140, 100, 100])\n",
    "    upper_pink = np.array([170, 255, 255])\n",
    "    mask = cv2.inRange(hsv_img, lower_pink, upper_pink)\n",
    "    result = cv2.bitwise_and(img, img, mask=mask)\n",
    "    return result\n",
    "\n",
    "def match_gestures(handedness, img2, threshold=110):\n",
    "    print(handedness)\n",
    "    img2_processed = preprocess_image(img2)\n",
    "    orb = cv2.ORB_create()\n",
    "    \n",
    "    for val in gestures:\n",
    "        des1_list = data[val]\n",
    "        des1 = np.array(des1_list)\n",
    "        kp2, des2 = orb.detectAndCompute(img2_processed, None)\n",
    "\n",
    "        if des1 is not None and des2 is not None and len(des1) > 0 and len(des2) > 0:\n",
    "            if des1.dtype != np.uint8:\n",
    "                des1 = des1.astype(np.uint8)\n",
    "            if des2.dtype != np.uint8:\n",
    "                des2 = des2.astype(np.uint8)\n",
    "\n",
    "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "            matches = bf.match(des1, des2)\n",
    "            matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "            if len(matches) > threshold:\n",
    "                print(\"The gestures are similar.\")\n",
    "                if val == \"to_right\" and handedness == \"Right\":\n",
    "                    return \"to_left\"\n",
    "                elif val == \"to_left\" and handedness == \"Left\":\n",
    "                    return \"to_right\"\n",
    "                else:\n",
    "                    return val\n",
    "        else:\n",
    "            print(\"One or both sets of descriptors are missing or empty.\")\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 256.0ms\n",
      "Speed: 3.3ms preprocess, 256.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 myright, 92.7ms\n",
      "Speed: 1.4ms preprocess, 92.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "\n",
      "0: 384x640 1 myright, 90.7ms\n",
      "Speed: 1.4ms preprocess, 90.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "\n",
      "0: 384x640 1 myright, 90.7ms\n",
      "Speed: 1.5ms preprocess, 90.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "\n",
      "0: 384x640 1 myright, 153.8ms\n",
      "Speed: 1.7ms preprocess, 153.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "\n",
      "0: 384x640 1 myright, 150.6ms\n",
      "Speed: 2.6ms preprocess, 150.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "\n",
      "0: 384x640 1 myright, 139.2ms\n",
      "Speed: 1.6ms preprocess, 139.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "\n",
      "0: 384x640 1 myright, 81.4ms\n",
      "Speed: 1.5ms preprocess, 81.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "\n",
      "0: 384x640 1 myright, 83.4ms\n",
      "Speed: 1.4ms preprocess, 83.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "\n",
      "0: 384x640 1 myright, 97.3ms\n",
      "Speed: 1.5ms preprocess, 97.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "\n",
      "0: 384x640 1 myright, 117.5ms\n",
      "Speed: 1.5ms preprocess, 117.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "\n",
      "0: 384x640 (no detections), 96.6ms\n",
      "Speed: 1.8ms preprocess, 96.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 myright, 139.2ms\n",
      "Speed: 2.0ms preprocess, 139.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "One or both sets of descriptors are missing or empty.\n",
      "\n",
      "0: 384x640 1 myleft, 1 myright, 188.9ms\n",
      "Speed: 2.7ms preprocess, 188.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "The gestures are similar.\n",
      "Right\n",
      "\n",
      "0: 384x640 1 myright, 173.0ms\n",
      "Speed: 5.0ms preprocess, 173.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "The gestures are similar.\n",
      "\n",
      "0: 384x640 1 myright, 89.5ms\n",
      "Speed: 1.7ms preprocess, 89.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "The gestures are similar.\n",
      "\n",
      "0: 384x640 1 myright, 109.4ms\n",
      "Speed: 1.5ms preprocess, 109.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "The gestures are similar.\n",
      "\n",
      "0: 384x640 1 myright, 114.9ms\n",
      "Speed: 1.5ms preprocess, 114.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "The gestures are similar.\n",
      "\n",
      "0: 384x640 1 myright, 99.2ms\n",
      "Speed: 1.4ms preprocess, 99.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "The gestures are similar.\n",
      "\n",
      "0: 384x640 1 myright, 115.5ms\n",
      "Speed: 3.7ms preprocess, 115.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "The gestures are similar.\n",
      "\n",
      "0: 384x640 1 myright, 105.5ms\n",
      "Speed: 2.4ms preprocess, 105.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "\n",
      "0: 384x640 1 myright, 109.3ms\n",
      "Speed: 1.6ms preprocess, 109.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "\n",
      "0: 384x640 1 myright, 106.1ms\n",
      "Speed: 2.3ms preprocess, 106.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "\n",
      "0: 384x640 1 myright, 1 yourleft, 105.6ms\n",
      "Speed: 1.9ms preprocess, 105.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Right\n",
      "\n",
      "0: 384x640 1 myright, 102.2ms\n",
      "Speed: 2.0ms preprocess, 102.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "\n",
      "0: 384x640 1 myright, 128.4ms\n",
      "Speed: 1.5ms preprocess, 128.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "\n",
      "0: 384x640 1 myright, 108.8ms\n",
      "Speed: 1.5ms preprocess, 108.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "\n",
      "0: 384x640 1 myright, 112.2ms\n",
      "Speed: 1.6ms preprocess, 112.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "\n",
      "0: 384x640 1 myright, 158.8ms\n",
      "Speed: 1.5ms preprocess, 158.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "\n",
      "0: 384x640 1 myright, 1 yourleft, 111.7ms\n",
      "Speed: 2.4ms preprocess, 111.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "The gestures are similar.\n",
      "Right\n",
      "\n",
      "0: 384x640 1 myright, 1 yourleft, 116.6ms\n",
      "Speed: 1.6ms preprocess, 116.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Right\n",
      "Right\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1) \n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  \n",
    "\n",
    "        #image loading\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.flip(image, 1)\n",
    "        results = hands.process(image)\n",
    "        canvas_for_yolo = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w, c = frame.shape\n",
    "\n",
    "        #for drawing\n",
    "        canvas = np.zeros_like(image)\n",
    "\n",
    "        #draw results on black canvas\n",
    "        if results.multi_hand_landmarks:\n",
    "            for handLMs in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    canvas, handLMs, mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2)\n",
    "                )\n",
    "            handedness = results.multi_handedness[0].classification[0].label\n",
    "    \n",
    "\n",
    "        width = canvas_for_yolo.shape[1]\n",
    "\n",
    "        #perform YOLO predictions\n",
    "        yolo_results = yolo_model.predict(frame)\n",
    "        for r in yolo_results:\n",
    "            #annotate boxes\n",
    "            annotator = Annotator(canvas)\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                b = box.xyxy[0]\n",
    "                mirrored_x_min = width - b[2]\n",
    "                mirrored_x_max = width - b[0]\n",
    "                mirrored_box = [mirrored_x_min-padding, b[1]-padding, mirrored_x_max+padding, b[3]+padding]\n",
    "                c = box.cls\n",
    "\n",
    "                #create cropped canvas for saving\n",
    "                save_me = canvas[max(int(mirrored_box[1]), 0):min(int(mirrored_box[3]), canvas.shape[0]),\n",
    "                               max(int(mirrored_box[0]), 0):min(int(mirrored_box[2]), canvas.shape[1])]\n",
    "\n",
    "                h, w = save_me.shape[:2]\n",
    "                current_aspect_ratio = w / h\n",
    "        \n",
    "                # Calculate padding\n",
    "                if current_aspect_ratio < desired_aspect_ratio:\n",
    "                    # Pad sides\n",
    "                    new_width = int(desired_aspect_ratio * h)\n",
    "                    pad_width = (new_width - w) // 2\n",
    "                    padded_image = cv2.copyMakeBorder(save_me, 0, 0, pad_width, pad_width, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "                else:\n",
    "                    # Pad top and bottom\n",
    "                    new_height = int(w / desired_aspect_ratio)\n",
    "                    pad_height = (new_height - h) // 2\n",
    "                    padded_image = cv2.copyMakeBorder(save_me, pad_height, pad_height, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        \n",
    "                # Resize image to standard size\n",
    "                resized_image = cv2.resize(padded_image, standard_size, interpolation=cv2.INTER_AREA)\n",
    "                base_img  = cv2.imread(\"base_gestures/start_base.png\")\n",
    "                start = match_gestures(handedness, resized_image)\n",
    "                \n",
    "                if len(start) != 0:\n",
    "                    cv2.putText(canvas, start, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                cv2.putText(canvas, \"Hand: \" + handedness, (50, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('s'):\n",
    "                    img_name = f\"cropped_hand_{img_counter}.png\"\n",
    "                    cv2.imwrite(\"saved_imgs/\" + img_name, resized_image)\n",
    "                    print(f\"{img_name} saved.\")\n",
    "                    img_counter += 1\n",
    "\n",
    "        #display\n",
    "        cv2.imshow('Hand Skeleton', canvas)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
